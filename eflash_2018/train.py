import argparse
import itertools
import matplotlib
import pickle
matplotlib.use('Qt5Agg')
import numpy as np
import h5py
import json
import os
import sys
from sklearn.ensemble import RandomForestClassifier
from sklearn.decomposition import PCA
from PyQt5 import QtCore, QtWidgets, QtGui
from PyQt5.QtWidgets import QShortcut
from PyQt5.QtGui import QKeySequence
from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg as FigureCanvas
from matplotlib.figure import Figure
import tqdm

def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument("--patch-file",
                        required=True,
                        help="The patch file generated by collect-patches")
    parser.add_argument("--output",
                        required=True,
                        help="The random forest model's pickle file")
    parser.add_argument("--n-components",
                        type=int,
                        default=32,
                        help="The number of components for the PCA "
                        "dimensionality reduction.")
    parser.add_argument("--max-samples",
                        type=int,
                        default=1000000,
                        help="The maximum number of samples for PCA "
                        "(subsample if there are more).")
    parser.add_argument("--neuroglancer",
                        help="The Neuroglancer image source, e.g. "
                        "precomputed://http://localhost:9000")
    parser.add_argument("--port",
                        type=int,
                        help="HTTP port for neurglancer server",
                        default=0)
    parser.add_argument("--bind-address",
                        help="The IP address to bind to as a webserver. "
                        "The default is 127.0.0.1 which is constrained to "
                        "the local machine.",
                        default="127.0.0.1")
    parser.add_argument("--static-content-source",
                        default=None,
                        help="The URL of the static content source, e.g. "
                        "http://localhost:8080 if being served via npm.")
    parser.add_argument("--n-jobs",
                        type=int,
                        default=-1,
                        help="How many simultaneous jobs to run while training "
                        "or predicting with the random forest.")
    return parser.parse_args()


class MPLCanvas(FigureCanvas):
    def __init__(self, parent):
        figure = Figure()
        self.axes_xy = figure.add_subplot(2, 2, 1)
        self.axes_xz = figure.add_subplot(2, 2, 2)
        self.axes_yz = figure.add_subplot(2, 2, 4)
        super(MPLCanvas, self).__init__(figure)
        self.setParent(parent)
        self.setSizePolicy(QtWidgets.QSizePolicy.Expanding,
                           QtWidgets.QSizePolicy.Expanding)
        self.updateGeometry()

    def show(self, image_xy, image_xz, image_yz):
        self.axes_xy.cla()
        self.axes_xy.imshow(image_xy, interpolation='bicubic')
        self.axes_xz.cla()
        self.axes_xz.imshow(image_xz, interpolation='bicubic')
        self.axes_yz.cla()
        self.axes_yz.imshow(image_yz, interpolation='bicubic')
        self.draw()


class ApplicationWindow(QtWidgets.QMainWindow):
    def __init__(self, patches_xy, patches_xz, patches_yz,
                 x, y, z, n_components, max_samples, n_jobs,
                 output_file, viewer):
        QtWidgets.QMainWindow.__init__(self)
        self.setAttribute(QtCore.Qt.WA_DeleteOnClose)
        self.setWindowTitle("Train")

        self.file_menu = QtWidgets.QMenu('&File', self)
        self.file_menu.addAction("&Save", self.fileSave)
        self.file_menu.addAction("&Write coordinates",
                                 self.fileWriteCoordinates)
        self.file_menu.addAction("&Train", self.fileTrain)
        self.file_menu.addAction('&Quit', self.fileQuit,
                                 QtCore.Qt.CTRL + QtCore.Qt.Key_Q)
        self.menuBar().addMenu(self.file_menu)
        self.save_shortcut = QShortcut(QKeySequence("Ctrl+S"), self)
        self.save_shortcut.activated.connect(self.fileSave)
        self.train_shortcut = QShortcut(QKeySequence("T"), self)
        self.train_shortcut.activated.connect(self.fileTrain)

        self.image_menu = QtWidgets.QMenu("&Image", self)
        self.image_menu.addAction("Ne&xt", self.imageNext)
        self.image_menu.addAction("Next &Positive", self.imageNextPositive)
        self.image_menu.addAction("Next &Negative", self.imageNextNegative)
        self.image_menu.addAction("Next &Unsure", self.imageNextUnsure)
        self.image_menu.addAction("&Go to", self.imageGoTo)
        self.menuBar().addMenu(self.image_menu)
        self.next_shortcut = QShortcut(QKeySequence("X"), self)
        self.next_shortcut.activated.connect(self.imageNext)
        self.next_positive_shortcut = QShortcut(QKeySequence("Ctrl+P"), self)
        self.next_positive_shortcut.activated.connect(self.imageNextPositive)
        self.next_negative_shortcut = QShortcut(QKeySequence("Ctrl+N"), self)
        self.next_negative_shortcut.activated.connect(self.imageNextNegative)
        self.next_unsure_shortcut = QShortcut(QKeySequence("U"), self)
        self.next_unsure_shortcut.activated.connect(self.imageNextUnsure)
        self.next_go_to_shortcut = QShortcut(QKeySequence("G"), self)
        self.next_go_to_shortcut.activated.connect(self.imageGoTo)

        self.mark_menu = QtWidgets.QMenu("&Mark", self)
        self.mark_menu.addAction("&Positive", self.markPositive)
        self.mark_menu.addAction("&Negative", self.markNegative)
        self.menuBar().addMenu(self.mark_menu)

        self.main_widget = QtWidgets.QWidget(self)

        l = QtWidgets.QVBoxLayout(self.main_widget)
        self.title_text = QtWidgets.QLabel()
        l.addWidget(self.title_text)
        self.canvas = MPLCanvas(self.main_widget)
        l.addWidget(self.canvas)

        self.unsure_text = QtWidgets.QLabel()
        l.addWidget(self.unsure_text)
        self.unsure_slider = QtWidgets.QSlider(QtCore.Qt.Horizontal)
        self.unsure_slider.setRange(0, 100)
        self.unsure_slider.setTickInterval(10)
        self.unsure_slider.setValue(50)
        self.unsure_slider.valueChanged.connect(self.on_slider_change)
        l.addWidget(self.unsure_slider)
        self.update_unsure_text()

        self.main_widget.setFocus()
        self.setCentralWidget(self.main_widget)
        icon_path = os.path.join(os.path.dirname(__file__), "training.png")
        self.setWindowIcon(QtGui.QIcon(icon_path))

        self.patches_xy = patches_xy
        self.patches_xz = patches_xz
        self.patches_yz = patches_yz
        n_patches = len(self.patches_xy)
        n_features = np.prod(self.patches_xy.shape[1:])
        patches = np.hstack(
            [_.reshape(n_patches, n_features)
             for _ in (patches_xy, patches_xz, patches_yz)])
        self.x, self.y, self.z = x, y, z
        self.n_jobs = n_jobs
        self.viewer = viewer
        self.output_file = output_file
        if os.path.exists(self.output_file):
            with open(self.output_file, "rb") as fd:
                d = pickle.load(fd)
                self.marks = d["marks"]
                self.pca = d["pca"]
                if self.pca.n_components != n_components:
                    self.train_pca(max_samples, n_components, patches)
                else:
                    self.classifier = d["classifier"]
                    if "predictions" in d:
                        self.predictions = d["predictions"]
                    if "pred_probs" in d:
                        self.pred_probs = d["pred_probs"]
                    self.pca_features = np.zeros((len(patches), n_components),
                                                 dtype=np.float32)
                    for idx0 in tqdm.tqdm(range(0, len(patches), max_samples),
                                          desc="PCA transform"):
                        idx1 = min(len(patches), idx0 + max_samples)
                        self.pca_features[idx0:idx1] =\
                            self.pca.transform(patches[idx0:idx1])
        else:
            self.marks = np.zeros(n_patches, np.int8)
            self.train_pca(max_samples, n_components, patches)
        self.imageNext()

    def train_pca(self, max_samples, n_components, patches):
        self.classifier = None
        self.pca = PCA(n_components=n_components)
        if len(patches) > max_samples:
            idxs = np.random.choice(len(patches), max_samples,
                                    replace=False)
            self.pca.fit(patches[idxs])
            self.pca_features = np.zeros((len(patches), n_components),
                                         dtype=np.float32)
            for idx0 in tqdm.tqdm(range(0, len(patches), max_samples),
                                  desc="PCA transform"):
                idx1 = min(len(patches), idx0 + max_samples)
                self.pca_features[idx0:idx1] = \
                    self.pca.transform(patches[idx0:idx1])
        else:
            self.pca_features = self.pca.fit_transform(patches)

    def get_unsure_cutoff_pct(self):
        return self.unsure_slider.value()

    def on_slider_change(self):
        self.update_unsure_text()

    def update_unsure_text(self):
        self.unsure_text.setText(
            "Unsure cutoff percent: %d" % self.get_unsure_cutoff_pct())

    def fileQuit(self):
        self.close()

    def closeEvent(self, ce):
        self.fileQuit()

    def fileSave(self):
        self.statusBar().showMessage("Saving...")
        object = dict(pca=self.pca,
                      classifier=self.classifier,
                      marks=self.marks,
                      predictions=self.predictions,
                      pred_probs=self.pred_probs,
                      x=self.x,
                      y=self.y,
                      z=self.z)
        with open(self.output_file, "wb") as fd:
            pickle.dump(object, fd)
        self.statusBar().showMessage("Saved to %s" % self.output_file)

    def fileWriteCoordinates(self):
        """Write a coordinates file using the current positives.

        """
        if self.classifier == None:
            self.statusBar().showMessage("Please train your model")
            return
        mask = self.predictions == 1
        coords = np.column_stack((self.x[mask], self.y[mask], self.z[mask]))
        filename, _ = QtWidgets.QFileDialog.getSaveFileName(
            self, "Save coordinates",
            filter="Coordinates (*.json);;All files (*)"
        )
        if filename:
            with open(filename, "w") as fd:
                json.dump(coords.tolist(), fd)

    def fileTrain(self):
        self.statusBar().showMessage("Training...")
        self.classifier = RandomForestClassifier(
            n_estimators=256,
            class_weight="balanced_subsample",
            oob_score=True,
            n_jobs = self.n_jobs)
        patches_xy = []
        patches_xz = []
        patches_yz = []
        classes = []
        for idx in np.where(self.marks != 0)[0]:
            for pxy, pxz, pyz in augment(self.patches_xy[idx],
                                         self.patches_xz[idx],
                                         self.patches_yz[idx]):
                patches_xy.append(pxy)
                patches_xz.append(pxz)
                patches_yz.append(pyz)
                classes.append(0 if self.marks[idx] == -1 else 1)
        n_patches = len(patches_xy)
        n_features = np.prod(patches_xy[0].shape)
        patches = np.hstack(
            [np.array(_).reshape(n_patches, n_features)
             for _ in (patches_xy, patches_xz, patches_yz)])
        classes = np.array(classes)
        pca_features = self.pca.transform(patches)

        self.classifier.fit(pca_features, classes)
        self.statusBar().showMessage("Predicting...")
        self.predictions = self.classifier.predict(self.pca_features)
        self.pred_probs = self.classifier.predict_proba(self.pca_features)
        self.statusBar().showMessage("Training complete: oob error = %.3f" %
                                     self.classifier.oob_score_)

    def imageNext(self):
        mask = np.where(self.marks == 0)[0]
        self.pick(mask)

    def pick(self, mask):
        self.idx = mask[np.random.randint(0, len(mask))]
        self.show_current()

    def show_current(self):
        if self.classifier is not None:
            self.title_text.setText(
                "x=%d, y=%d, z=%d, prob=%.3f" %
                (self.x[self.idx], self.y[self.idx], self.z[self.idx],
                 self.pred_probs[self.idx, 1])
            )
        if self.viewer is not None:
            with self.viewer.txn() as txn:
                txn.position.voxel_coordinates = [
                    self.x[self.idx], self.y[self.idx], self.z[self.idx]]
        self.canvas.show(self.patches_xy[self.idx],
                         self.patches_xz[self.idx],
                         self.patches_yz[self.idx])

    def imageNextPositive(self):
        if self.classifier is None:
            self.statusBar().showMessage(
                "Hey, how about training a classifier with the \"T\" key?")
            return
        mask = np.where((self.marks == 0) &
                        (self.predictions == 1))[0]
        self.pick(mask)

    def imageNextNegative(self):
        if self.classifier is None:
            self.statusBar().showMessage(
                "Hey, how about training a classifier with the \"T\" key?")
            return
        mask = np.where((self.marks == 0) &
                        (self.predictions == 0))[0]
        self.pick(mask)

    def imageNextUnsure(self):
        if self.classifier is None:
            self.statusBar().showMessage(
                "Hey, how about training a classifier with the \"T\" key?")
            return
        unmarked = np.where(self.marks == 0)[0]
        unsure_cutoff = self.get_unsure_cutoff_pct() / 100
        order = np.argsort(np.abs(self.pred_probs[unmarked, 1] - unsure_cutoff))
        idx = np.random.randint(0, min(len(order), max(len(order) // 100, 10 )))
        self.idx = unmarked[order[idx]]
        self.show_current()

    def imageGoTo(self):
        with self.viewer.txn() as txn:
            coordinates = txn.voxel_coordinates
            distances = np.sum(np.square(
                np.column_stack((self.x, self.y, self.z)) -
                np.array(coordinates).reshape(1, 3)), 1)
            min_idx = np.argmin(distances)
        self.idx = min_idx
        self.show_current()

    def markPositive(self):
        self.marks[self.idx] = 1

    def markNegative(self):
        self.marks[self.idx] = -1


def augment(xy_patch, xz_patch, yz_patch):
    """Return a sequence reflected and rotated patches

    The Z direction is not symmetric - objects tend to have an anti-shadow
    downward, so we leave that alone and also don't rotate in Z. Arguably,
    there are more subtle artifacts in X and Y that would prevent you from
    switching axes or from flipping directions, but it's probably more
    worthwhile to train on the augmented set than not.

    :param xy_patch:
    :param xz_patch:
    :param yz_patch:
    :return: a sequence with reflected and rotated patches. Each element of
    the sequence is a 3-tuple of patches.
    """
    identity_slice = slice(None)
    reflect_slice = slice(None, None, -1)
    result = []
    for xs, ys, transpose in itertools.product(
            (identity_slice, reflect_slice),
            (identity_slice, reflect_slice),
            (False, True)):
        xy_patch_out = xy_patch[ys, xs]
        xz_patch_out = xz_patch[:, xs]
        yz_patch_out = yz_patch[:, ys]
        if transpose:
            xz_patch_out, yz_patch_out = yz_patch_out, xz_patch_out
            xy_patch_out = xy_patch_out.transpose()
        result.append((xy_patch_out, xz_patch_out, yz_patch_out))
    return result


def main():
    app = QtWidgets.QApplication(sys.argv)
    args = parse_args()
    with h5py.File(args.patch_file, "r") as fd:
        patches_xy = fd["patches_xy"][:]
        patches_xz = fd["patches_xz"][:]
        patches_yz = fd["patches_yz"][:]
        x = fd["x"][:]
        y = fd["y"][:]
        z = fd["z"][:]
    if args.neuroglancer is None:
        viewer = None
    else:
        import neuroglancer
        import webbrowser
        if args.static_content_source is not None:
            neuroglancer.set_static_content_source(
                url=args.static_content_source)
        neuroglancer.set_server_bind_address(
            args.bind_address, bind_port=args.port)
        viewer = neuroglancer.Viewer()
        print("Neuroglancer URL: %s" % str(viewer))
        with viewer.txn() as txn:
            txn.layers["image"] = neuroglancer.ImageLayer(
                source=args.neuroglancer
            )
        webbrowser.open_new(viewer.get_viewer_url())
    window = ApplicationWindow(patches_xy, patches_xz, patches_yz,
                               x, y, z, args.n_components,
                               args.max_samples,
                               args.n_jobs, args.output, viewer)
    window.setWindowTitle("Train")
    window.show()
    sys.exit(app.exec())

if __name__=="__main__":
    main()
